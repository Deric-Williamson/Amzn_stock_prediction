{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/amzn_final_dataset.csv',index_col='AMZN')\n",
    "df.dropna(inplace=True)\n",
    "df['c_four_percent_high'] = df['c_four_percent_high'].map({'Buy': 1, '0': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "grad_boost =  GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "models = [knn, dtc, xgb, svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() \n",
      "\n",
      "Precision Training Score: 100.00%\n",
      "Precision Test Score: 54.55%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "====================================================== \n",
      "\n",
      "\n",
      "DecisionTreeClassifier() \n",
      "\n",
      "Precision Training Score: 61.08%\n",
      "Precision Test Score: 57.38%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "====================================================== \n",
      "\n",
      "\n",
      "XGBClassifier() \n",
      "\n",
      "Precision Training Score: 100.00%\n",
      "Precision Test Score: 66.67%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "====================================================== \n",
      "\n",
      "\n",
      "SVC() \n",
      "\n",
      "Precision Training Score: 0.00%\n",
      "Precision Test Score: 0.00%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "====================================================== \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "#indexes = [-2500,-2000,-1500,-1000,-500,-300,-200]\n",
    "indexes = [-1500]\n",
    "\n",
    "for index in indexes:\n",
    "    a = df.iloc[index: ]\n",
    "\n",
    "\n",
    "    y = a['c_four_percent_high']\n",
    "\n",
    "    x = a[['SMA', 'Stochastic','RSI', 'ROC', 'ATR', 'ADX',\n",
    "           'ADX_diff', 'SMA_diff', 'Stochastic_diff', 'RSI_diff', 'ROC_diff', 'ATR_diff',\n",
    "           'rsi_over_80','rsi_over_70','rsi_over_60','rsi_under_40','rsi_under_30','rsi_under_20',\n",
    "           'Open', 'High', 'Low', 'Close'\n",
    "           ]]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)    \n",
    "    \n",
    "    scaled_x_train = scaler.fit_transform(x_train)\n",
    "    scaled_x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        if model == knn:\n",
    "            param_grid = {\n",
    "                   'n_neighbors': [3,5,7,11,19],\n",
    "                   'weights': ['uniform', 'distance'],\n",
    "                   'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                   'metric' : ['minkowski', 'euclidean', 'manhattan']}\n",
    "\n",
    "        if model == dtc:\n",
    "            param_grid = {\n",
    "                   'criterion': ['gini', 'entropy'],\n",
    "                   'max_depth': [2, 3, 4, 5, 6],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "\n",
    "\n",
    "        if model == xgb:\n",
    "            param_grid = {\n",
    "                    'n_estimators': [100, 150, 200, 250],\n",
    "                    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "                    'max_depth': [3,4,5,6,7,8,9]}\n",
    "\n",
    "        if model == svm:\n",
    "            param_grid = {\n",
    "                    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "                    'kernel': ['linear']}\n",
    "\n",
    "\n",
    "    #     for score in scores:\n",
    "\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, return_train_score=True, scoring = 'precision')\n",
    "\n",
    "        if model == knn or model == svm:\n",
    "            grid_search.fit(scaled_x_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            #Mean training score\n",
    "            train_model = best_model.predict(scaled_x_train)\n",
    "            train_score = precision_score(y_train, train_model)\n",
    "\n",
    "            #Mean test score\n",
    "            test_model = best_model.predict(scaled_x_test)\n",
    "            test_score = precision_score(y_test, test_model)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            grid_search.fit(x_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            #Mean training score\n",
    "            train_model = best_model.predict(x_train)\n",
    "            train_score = precision_score(y_train, train_model)\n",
    "\n",
    "            #Mean test score\n",
    "            test_model = best_model.predict(x_test)\n",
    "            test_score = precision_score(y_test, test_model)\n",
    "\n",
    "        print(model, '\\n')\n",
    "        print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "        print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "        print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print('====================================================== \\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1500 rows seems to be good starting place on how many rows to incorporate\n",
    "\n",
    "> knn has overfitting problems\n",
    "> svc has to have very small data set to work\n",
    "\n",
    "> Decision Tree and XGB seems to be a good starting place on models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the grid search: I am running grid-searches over differ train/test subsets, deleting any hyper parameters that might lead to over fitting or low precision scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changed x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.iloc[-1500: ]\n",
    "\n",
    "y = a['c_four_percent_high']\n",
    "\n",
    "x = a[['SMA', 'ROC', 'ATR', 'ADX',\n",
    "        'High', 'Low', 'Close'\n",
    "       ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.669118</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.592391</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.565749</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train      test criterion max_depth min_samples_leaf min_samples_split\n",
       "2   0.978723  0.800000   entropy         4                6                 2\n",
       "4   0.796610  0.777778      gini         3                1                 2\n",
       "3   0.800000  0.769231      gini         3                1                 2\n",
       "10  0.737179  0.685714      gini         4                4                10\n",
       "21  0.669118  0.676471      gini         3                1                 2\n",
       "0   0.586957  0.675000      gini         2                1                 2\n",
       "16  0.627737  0.647059      gini         2                1                 2\n",
       "8   0.592391  0.636364      gini         2                1                 2\n",
       "11  0.681159  0.636364   entropy         4                1                 5\n",
       "17  0.656522  0.625000      gini         4                2                 2\n",
       "24  0.606742  0.609756      gini         2                1                 2\n",
       "22  0.776119  0.600000      gini         3                6                 2\n",
       "7   0.693431  0.593750      gini         3                3                 2\n",
       "5   0.615385  0.576923      gini         2                1                 2\n",
       "19  0.707207  0.574074      gini         4                1                 2\n",
       "9   0.682759  0.560000      gini         3                1                 2\n",
       "1   0.798246  0.545455   entropy         4                5                 2\n",
       "20  0.675676  0.539683   entropy         4                4                 5\n",
       "23  0.617486  0.533333      gini         2                1                 2\n",
       "18  0.761290  0.529412   entropy         4                1                 2\n",
       "12  0.744444  0.527778      gini         4                6                 5\n",
       "14  0.565749  0.500000   entropy         3                1                 2\n",
       "13  0.615385  0.490566      gini         2                1                 2\n",
       "15  0.721053  0.488372   entropy         4                6                 5\n",
       "6   0.764706  0.411765   entropy         4                2                 5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "b = pd.DataFrame(columns = ['train', 'test', 'criterion', 'max_depth', 'min_samples_leaf', 'min_samples_split'])\n",
    "\n",
    "for i in range(25): \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "    param_grid = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3, 4],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "    grid_search = GridSearchCV(dtc, param_grid, cv=3, return_train_score=True, scoring = 'precision')\n",
    "\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    train_model = best_model.predict(x_train)\n",
    "\n",
    "    test_model = best_model.predict(x_test)\n",
    "\n",
    "    train_score = precision_score(y_train, train_model)\n",
    "    test_score = precision_score(y_test, test_model)\n",
    "\n",
    "\n",
    "    b.loc[i] = [train_score,\n",
    "                test_score,\n",
    "                grid_search.best_params_['criterion'],\n",
    "                grid_search.best_params_['max_depth'],\n",
    "                grid_search.best_params_['min_samples_leaf'],\n",
    "                grid_search.best_params_['min_samples_split']]\n",
    "    \n",
    "b.sort_values(by='test', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state : 790\n",
      "train precision score : 0.86\n",
      "test precision score : 0.84\n",
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
      "test recall score : 0.21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(790, 800): \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=i)\n",
    "\n",
    "    param_grid = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3, 4],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "    grid_search = GridSearchCV(dtc, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    train_model = best_model.predict(x_train)\n",
    "\n",
    "    test_model = best_model.predict(x_test)\n",
    "\n",
    "    train_score = precision_score(y_train, train_model)\n",
    "    test_score = precision_score(y_test, test_model)\n",
    "    \n",
    "    recall_test = recall_score(y_test, test_model)\n",
    "\n",
    "\n",
    "    diff = abs(train_score - test_score)\n",
    "    \n",
    "    if test_score > .69 and diff < .05 and recall_test > .11:\n",
    "        print('random_state :',i)\n",
    "        print('train precision score :', round(train_score,2))\n",
    "        print('test precision score :', round(test_score,2))\n",
    "        print(grid_search.best_params_)\n",
    "        print('test recall score :', round(recall_test,2))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Choices:\n",
    "_________\n",
    "\n",
    "random_state : 790  \n",
    "train precision score : 0.86  \n",
    "test precision score : 0.84  \n",
    "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}  \n",
    "test recall score : 0.21  \n",
    "\n",
    "    ------------\n",
    "    | 93 | 354 |\n",
    "    ------------\n",
    "    | 16 | 1040|  \n",
    "    ------------\n",
    "  \n",
    "  \n",
    "  \n",
    "random_state : 711  \n",
    "train precision score : 0.75  \n",
    "test precision score : 0.74  \n",
    "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2}  \n",
    "test recall score : 0.27   \n",
    "\n",
    "    -------------\n",
    "    | 141 | 306 |\n",
    "    -------------\n",
    "    | 47 | 1030 |  \n",
    "    -------------\n",
    "    \n",
    "random_state : 253  \n",
    "train precision score : 0.8  \n",
    "test precision score : 0.76  \n",
    "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 10}  \n",
    "test recall score : 0.24  \n",
    "\n",
    "    -------------\n",
    "    | 130 | 317 |\n",
    "    -------------\n",
    "    | 33  | 1020|  \n",
    "    -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I am moving foward with the random state of 790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['c_four_percent_high']\n",
    "\n",
    "x = df[['SMA', 'ROC', 'ATR', 'ADX',\n",
    "        'High', 'Low', 'Close'\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Training Score: 100.00%\n",
      "Precision Test Score: 61.18%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'learning_rate': 0.5, 'n_estimators': 200}\n",
      "====================================================== \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=1, min_samples_split=2)\n",
    "ada = AdaBoostClassifier(base_estimator=dtc)\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [100,150, 200, 250],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5]}\n",
    "\n",
    "grid_search = GridSearchCV(ada, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Mean training score\n",
    "train_model = best_model.predict(x_train)\n",
    "train_score = precision_score(y_train, train_model)\n",
    "\n",
    "#Mean test score\n",
    "test_model = best_model.predict(x_test)\n",
    "test_score = precision_score(y_test, test_model)\n",
    "\n",
    "print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "print('====================================================== \\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Training Score: 88.36%\n",
      "Precision Test Score: 67.86%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'deviance', 'n_estimators': 375}\n",
      "====================================================== \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grad3 = GradientBoostingClassifier(init=dtc)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [375],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'criterion': ['friedman_mse', 'mse']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(grad_boost, param_grid, cv=3, return_train_score=True, scoring = 'precision')\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Mean training score\n",
    "train_model = best_model.predict(x_train)\n",
    "train_score = precision_score(y_train, train_model)\n",
    "\n",
    "#Mean test score\n",
    "test_model = best_model.predict(x_test)\n",
    "test_score = precision_score(y_test, test_model)\n",
    "\n",
    "print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "print('====================================================== \\n\\n')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
