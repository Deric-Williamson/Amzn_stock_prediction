{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to find the best models to go forward with.  \n",
    "Using gridsearchCV for hyper-parameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/amzn_final_dataset.csv',index_col='AMZN')\n",
    "df.dropna(inplace=True)\n",
    "df['c_four_percent_high'] = df['c_four_percent_high'].map({'Buy': 1, '0': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best estimator models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.iloc[-1500: ]\n",
    "\n",
    "y = a['c_four_percent_high']\n",
    "\n",
    "x = a[['SMA', 'ROC', 'ATR', 'ADX',\n",
    "        'High', 'Low', 'Close'\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">After running the Decision Tree feature importance in the modeling notebook. Only a handful of features are necessary for the same predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction model is very sensitive to change.  \n",
    "In this for loop, I run the gridsearch several times and put it in a data frame to help limit any grid search parameters that causes fitting issues or bad estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.572973</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.582857</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.612378</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676617</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.663717</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.607735</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.619289</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train      test criterion max_depth min_samples_leaf min_samples_split\n",
       "13  0.884058  0.866667   entropy         4                1                10\n",
       "22  0.586022  0.714286      gini         2                1                 2\n",
       "21  0.572973  0.714286      gini         2                1                 2\n",
       "10  0.713115  0.696970   entropy         4                6                 2\n",
       "7   0.586592  0.690476      gini         2                1                 2\n",
       "24  0.821053  0.666667   entropy         4                5                 2\n",
       "12  0.582857  0.660377   entropy         2                1                 2\n",
       "11  0.882979  0.653846   entropy         4                1                 2\n",
       "18  0.803419  0.653846   entropy         4                5                 5\n",
       "1   0.586592  0.653061      gini         2                6                 5\n",
       "16  0.649682  0.641026   entropy         3                1                10\n",
       "23  0.592593  0.641026   entropy         2                1                 2\n",
       "2   0.676259  0.633333      gini         3                4                 2\n",
       "4   0.758621  0.628571      gini         4                4                 5\n",
       "15  0.643836  0.609375      gini         4                4                 2\n",
       "0   0.612378  0.600000      gini         4                4                 5\n",
       "3   0.676617  0.541667   entropy         4                4                 2\n",
       "5   0.654762  0.533333   entropy         3                1                 2\n",
       "8   0.663717  0.529412      gini         4                3                 2\n",
       "19  0.708333  0.525000   entropy         4                3                10\n",
       "17  0.607735  0.518519      gini         2                1                 2\n",
       "20  0.577670  0.517241   entropy         2                1                 2\n",
       "14  0.619289  0.470588   entropy         3                1                 2\n",
       "9   0.593220  0.466667      gini         3                1                 2\n",
       "6   0.708108  0.452830   entropy         4                4                 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "b = pd.DataFrame(columns = ['train', 'test', 'criterion', 'max_depth', 'min_samples_leaf', 'min_samples_split'])\n",
    "\n",
    "for i in range(25): \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "    param_grid = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3, 4],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "    grid_search = GridSearchCV(dtc, param_grid, cv=3, return_train_score=True, scoring = 'precision')\n",
    "\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    train_model = best_model.predict(x_train)\n",
    "\n",
    "    test_model = best_model.predict(x_test)\n",
    "\n",
    "    train_score = precision_score(y_train, train_model)\n",
    "    test_score = precision_score(y_test, test_model)\n",
    "\n",
    "\n",
    "    b.loc[i] = [train_score,\n",
    "                test_score,\n",
    "                grid_search.best_params_['criterion'],\n",
    "                grid_search.best_params_['max_depth'],\n",
    "                grid_search.best_params_['min_samples_leaf'],\n",
    "                grid_search.best_params_['min_samples_split']]\n",
    "    \n",
    "b.sort_values(by='test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the sensitivity of the dataset, I played with several random_state integers to find the best model.  \n",
    "In this model, I am looking for a precision score higher than .69 (good investments vs bad investments) that doesn't over fit, with a recall score higher than .2 (limit how many missed opportunities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state : 790\n",
      "train precision score : 0.86\n",
      "test precision score : 0.84\n",
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 10}\n",
      "test recall score : 0.21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(790, 800): \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=i)\n",
    "\n",
    "    param_grid = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3, 4],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "    grid_search = GridSearchCV(dtc, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    train_model = best_model.predict(x_train)\n",
    "\n",
    "    test_model = best_model.predict(x_test)\n",
    "\n",
    "    train_score = precision_score(y_train, train_model)\n",
    "    test_score = precision_score(y_test, test_model)\n",
    "    \n",
    "    recall_test = recall_score(y_test, test_model)\n",
    "\n",
    "\n",
    "    diff = abs(train_score - test_score)\n",
    "    \n",
    "    if test_score > .69 and diff < .05 and recall_test > .11:\n",
    "        print('random_state :',i)\n",
    "        print('train precision score :', round(train_score,2))\n",
    "        print('test precision score :', round(test_score,2))\n",
    "        print(grid_search.best_params_)\n",
    "        print('test recall score :', round(recall_test,2))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Choices:\n",
    "_________\n",
    "\n",
    "random_state : 790  \n",
    "train precision score : 0.86  \n",
    "test precision score : 0.84  \n",
    "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}  \n",
    "test recall score : 0.21  \n",
    "\n",
    "    ------------\n",
    "    | 93 | 354 |\n",
    "    ------------\n",
    "    | 16 | 1040|  \n",
    "    ------------\n",
    "      \n",
    "    \n",
    "    \n",
    "random_state : 711  \n",
    "train precision score : 0.75  \n",
    "test precision score : 0.74  \n",
    "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2}  \n",
    "test recall score : 0.27   \n",
    "\n",
    "    -------------\n",
    "    | 141 | 306 |\n",
    "    -------------\n",
    "    | 47 | 1030 |  \n",
    "    -------------\n",
    "        \n",
    "          \n",
    "          \n",
    "random_state : 253  \n",
    "train precision score : 0.8  \n",
    "test precision score : 0.76  \n",
    "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 10}  \n",
    "test recall score : 0.24  \n",
    "\n",
    "    -------------\n",
    "    | 130 | 317 |\n",
    "    -------------\n",
    "    | 33  | 1020|  \n",
    "    -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Top three parameters with tweaked random states.   \n",
    "> Each model has something good.  \n",
    "> I am moving forward with the random state of 790."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble models will take the base model as a best estimator to help with performance of overall model and to help with the stability of newer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> base model - Decision Tree()  \n",
    ">{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 10}  \n",
    "> random_state: 790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = a['c_four_percent_high']\n",
    "\n",
    "x = a[['SMA', 'ROC', 'ATR', 'ADX',\n",
    "        'High', 'Close'\n",
    "       ]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=790)\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion='gini',\n",
    "                             max_depth=4,\n",
    "                             min_samples_leaf=6,\n",
    "                             min_samples_split=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Training Score: 80.34%\n",
      "Precision Test Score: 63.64%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "            'criterion': ['gini'],\n",
    "            'max_depth': [4],\n",
    "            'min_samples_leaf': [6],\n",
    "            'min_samples_split': [2],\n",
    "            'n_estimators': [800]}\n",
    "\n",
    "grid_search = GridSearchCV(forest, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Mean training score\n",
    "train_model = best_model.predict(x_train)\n",
    "train_score = precision_score(y_train, train_model)\n",
    "\n",
    "#Mean test score\n",
    "test_model = best_model.predict(x_test)\n",
    "test_score = precision_score(y_test, test_model)\n",
    "\n",
    "print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Training Score: 85.71%\n",
      "Precision Test Score: 84.00%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'learning_rate': 0.001, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=dtc)\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [25],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5]}\n",
    "\n",
    "grid_search = GridSearchCV(ada, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Mean training score\n",
    "train_model = best_model.predict(x_train)\n",
    "train_score = precision_score(y_train, train_model)\n",
    "\n",
    "#Mean test score\n",
    "test_model = best_model.predict(x_test)\n",
    "test_score = precision_score(y_test, test_model)\n",
    "\n",
    "print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Training Score: 85.71%\n",
      "Precision Test Score: 84.00%\n",
      "Best Parameter Combination Found During Grid Search:\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.001, 'loss': 'deviance', 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "grad_boost = GradientBoostingClassifier(init=dtc)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [30],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'criterion': ['friedman_mse', 'mse']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(grad_boost, param_grid, cv=3, return_train_score=True, scoring = 'precision', n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#Mean training score\n",
    "train_model = best_model.predict(x_train)\n",
    "train_score = precision_score(y_train, train_model)\n",
    "\n",
    "#Mean test score\n",
    "test_model = best_model.predict(x_test)\n",
    "test_score = precision_score(y_test, test_model)\n",
    "\n",
    "print(f\"Precision Training Score: {train_score :.2%}\")\n",
    "print(f\"Precision Test Score: {test_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently moving forward with the Decision Tree as a base model.  \n",
    "> K Nearest Neighbors and SVC models both struggled with extreme over fitting.  \n",
    "> Xgb models seemed to work decently at first and definitely worth looking into for future works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am moving forward with the Gradient Boosting ensemble method to help with the performance of the base model.    \n",
    "Currently with the Decision Tree Classifier as the base, The over fit is less with more option as parameters for future proofing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
